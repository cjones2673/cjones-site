<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Benefits and Drawbacks of Generative AI Use for Programming Work</title>
    <link rel="stylesheet" href="ai_style.css">
</head>
<body>
    <h1>The Benefits and Drawbacks of Generative AI Use for Programming Work</h1>
    <h2>Christopher Jones</h2>
    <h3>3 November 2024</h3>

    <p>
        Imagine you’ve just completed the most difficult assignment you’ve ever had to do for class. It took you hours of hard work, scouring the internet for answers, trying to piece everything together, but you’ve finally done it. As relief washes over you, you look to your classmate. He’s had the assignment done for days. It didn’t even take him an hour. How is it possible that someone could complete such a difficult task so quickly? The answer: he didn’t. He made an AI model do it for him. He fed it the prompt and it generated an output, and he was able to have the assignment completed days in advance. Unfair, isn’t it? This is, unfortunately, a reality for a lot of students nowadays. As generative AI models are becoming better at producing human-like outputs, AI use among students is becoming more and more widespread. As a result, students who are not unethically using AI to do work for them may feel like they are being left behind. 
    </p>
    <p>
        There is a silver lining, however. In the example above, the student who did their work honestly is much more likely to get a better grade than the student who used AI to do his work. The fact of the matter is that while generative AI is extremely quick at generating human-like responses, it’s still in its early stages, and thus, isn’t all that great at it yet. AI detection software is still pretty reliable and the overall quality of content generated by AI is still relatively incomparable to that of a human. Still, the nature of AI and the content it generates begs the question: is there a middle ground, and, furthermore, how can we utilize this up-and-coming tool to benefit our work in the best way possible. Certainly, there is a midpoint between “AI is strictly beneficial and should always be used,” and “AI is strictly detrimental and should never be used.” So, where is it? 
    </p>
    <p>
        While the question of whether AI-generated content is good or bad for creators applies to nearly every field of work and study, this report will focus solely on the field of computer science and programming, as AI-generated code has become a foundational issue in the field, and an extremely controversial one at that. This report will seek to provide insight into the issue of generative AI and its role in the work of programmers, its benefit as a tool for efficient programming, the dangers of over-reliance on the code it generates, and ultimately, how humans can use it to best benefit their work, and where it is best used in the workplace.
    </p>

    <h3>Literature Review</h3>
    <p>
        Generative artificial intelligence (AI) models such as OpenAI’s ChatGPT, Google’s Gemini, or Microsoft’s Copilot can be used to write large amounts of code instantly, and it’s getting better at it as time goes on. As generative AI keeps growing and taking the world by storm, even going so far as to threaten the jobs of journalists, artists and other creative workers, many programmers are left wondering what it means for them. Is generative AI a threat to programming work? Are programmers becoming too dependent on AI use? 
    </p>
    <p>
        While generative AI does seem a little scary at first, given how vast its capabilities are, it’s certainly worth considering that this new tool isn’t all bad, and may actually be primarily beneficial to the work of experienced programmers, allowing them to write large amounts of code more efficiently and effectively. According to research conducted in February 2023 by Microsoft researcher Dr. Sida Peng, who earned his PhD from Cornell University in 2017, “[AI] has a statistically and practically significant impact on productivity…” (7). The research Dr. Peng and his team conducted in 2023 concluded that professional developers who have access to generative AI tools are able to complete tasks 55.8% faster than those who do not (Peng et al. 7).
    </p>
    <p>
        This would certainly indicate that AI use can increase developer productivity, and should thus be used by professional programmers in order to complete their work more efficiently. However, it is certainly worth considering the fact that the participants in the 2023 study were professionals, who had, on average, 6 years of coding experience and spent 9 hours a day programming (Peng et al. 5). The article does not address how AI use affects the productivity of programmers who are less experienced, who may work less efficiently to begin with and not know how to work with the material that is generated for them by the AI model. As a result, less experienced programmers may be more likely to just incorporate the code generated for them by the AI model without thinking twice about it, potentially allowing them to complete the task more quickly, but also putting themselves at risk of implementing solely AI-generated code.
    </p>
    <p>
        The implementation of AI-generated code wouldn’t be such an issue if the code generated by the AI model didn’t come with an array of bugs, logical errors, and security vulnerabilities. According to a review by Yue Liu et al. in June 2024 of ChatGPT-generated solutions to a set of 2,033 programming tasks, “...While ChatGPT can generate functional code for various programming tasks, the generated code often suffers from quality issues, such as compilation errors, wrong outputs, maintainability problems, and performance insufficiencies” (23). The research conducted by Liu et al. in 2023, among many, many others, indicates that AI-generated code simply falls short compared to that of human programmers. Since AI-generated code is significantly worse than code written by a programmer, it’s going to make a real programmer’s work significantly worse when they opt to use it instead of completing a task for themselves. Using AI-generated code in order to increase efficiency is okay when you know the code that is being generated can be reviewed by someone who knows what they’re doing, to make sure that the code being implemented isn’t full of errors, but the problem lies in the fact that AI-generated code is usually implemented without review by a novice programmer, who is incapable of detecting errors on their own. 
    </p>
    <p>
        Many researchers have expressed concern that novice developers are becoming overly reliant on AI-generated code. “...Since [generative AI] entered the mainstream, researchers have been concerned about the possibility of student over-reliance” (Prather et al. 470). If novice programmers become overly reliant on AI-generated code, it can actually stunt the development of foundational knowledge of programming and their ability to think critically. This is especially concerning to AI researchers because as AI becomes more widespread, it’s going to become even more difficult for students to complete their work, because their foundational programming knowledge is going to be based on bad code generated by an AI model, which is just going to make them even more reliant on code-generating tools. “If GenAI is replacing critical thinking in programming problem solving, rather than supporting it, then it stands to reason that metacognitive difficulties faced by novice programmers could get worse with GenAI tools as well” (Prather et al. 470). As novice programmers become more reliant on AI, they begin learning less and less. If the machine can do everything for them, what’s the point in learning how to do it themselves? This is certainly detrimental to their cognitive ability as a programmer, and is likely going to make them more lazy, which will just make them more reliant on the machine to do everything for them. It is for these reasons that AI is clearly detrimental to the learning of novice programmers. People who are learning how to code should not be using something that can generate limitless amounts of code for them instantly, because if they just begin using that, they’re never going to even want to learn how to code. Studies reviewed by Chunpeng Zhai et al. in June 2024 indicate that an over-reliance on AI models to complete tasks for students can “potentially impair critical cognitive skills such as critical thinking, decision-making and analytical thinking” (2). AI use among students is clearly stunting their learning, and that’s just going to make them want to use it more. If they aren’t writing their own code and using it, and instead just having the machine do it for them, they aren’t engaging themselves with their work, and it’s going to make them less motivated and the code that they themselves write is going to start becoming worse.
    </p>
    
    <h3>Methods</h3>
    <p>
        The sources collected for this report were found on Google Scholar, and they are articles published by distinguished scholars who exhibit strong ethos through their work and research experience. All articles are very recent, the earliest published in February 2023 and the latest in August 2024. The articles are strong for both of these reasons and they are also extremely relevant to the subject matter, with each of them having documented research experiments on the effects of generative AI use on programmers. The results of this research support various hypotheses, each exhibiting evidence suggesting a different viewpoint regarding AI use. In bringing each of these sources together, this report seeks to demonstrate the various benefits and drawbacks of AI use among professionals and students, and whether or not it can be used to promote efficiency and functionality of the code they write. 
    </p>
    <p>
        The primary research conducted for this report is an interview with a member of WVU faculty who is vastly knowledgeable in the field of technology and programming, who certainly offers valuable insight on the topic of generative AI, and whether he believes its use is beneficial or detrimental to programming work.
    </p>
    <p>
        Dr. Tom Devine is a member of WVU faculty whose name holds a lot of weight in the University’s Computer Science department. Devine earned his PhD in Computer Science at West Virginia University in 2020. He taught programming, software engineering, and ethics at Fairmont State University for 5 years before beginning at WVU in 2020, where he continues to this day to teach programming, software engineering and cybersecurity. Devine gave a presentation at the West Virginia Press Association 2024 Conference on August 10th titled “The Dark Side of AI,” on the topic of AI’s role in job displacement, ethics, disinformation, and education. On October 24, 2024, in order to shed some light on AI’s role in the programming world, an interview was conducted with Dr. Devine regarding what he knows about AI’s role among programmers as a professor of Computer Science. Devine was questioned on various topics, including advantages and disadvantages of generative AI as a programming support tool, whether AI can be used to increase developer productivity, the overall quality of AI-generated code, how AI use can affect students’ learning, ethical concerns of AI use, whether AI poses a threat to computer science jobs, among others. The interview provided an extensive amount of helpful and insightful information regarding the issue of AI use for developers. 
    </p>
    
    <h3>Results</h3>
    <p>
        In the interview, Devine expressed concern that students who use AI for their classwork are creating code that does not work properly and is insecure. “So, the idea is that students who have no idea how to write code will use the AI to write the code, and they won’t understand what’s happening,” Devine says. “Just because a program works does not mean it’s good or correct… [The AI models] are trained on all the bad code that’s already out there, that’s full of vulnerabilities.” However, bad code isn’t the only issue of AI use among students that Devine highlights, nor is it remotely the worst. Cognitive atrophy is a key concept that was touched on in the interview, and also in Devine’s WVPA presentation. Students can often become over-reliant on AI models that write code for them, causing them to misunderstand key concepts, and not know how to write good code on their own. “For a student who’s trying to learn something, they end up with the cognitive atrophy because you cannot copy-paste your way to intelligence,” Devine says. “If you’re copy-pasting, [neural] pathways are not being strengthened, so you’re not learning anything, right?” “...If you do not exercise your brain, it becomes weak, and then your weak brain is unable to do things in the real world.” Clearly, cognitive atrophy is a major issue that should make any student wary of AI use for their coursework. Generally, it seems that Dr. Devine is critical of AI use for beginner programmers. However, he does believe that it can be used for programmers who already know what they’re doing, just to make their lives a little bit easier. “It’s a force multiplier for the people that know what they’re doing to do some of the mundane stuff that nobody wants to do… That’s what computers have always been good at. Mundane, repetitive tasks that are simple to do but take a lot of time.” So, according to Devine, AI can be used by professionals to complete simple, mundane, easy tasks so that they can work more efficiently. This lines up with the Copilot research conducted by Peng et al. in 2023. People who already know what they are doing are able to get their work done much quicker if they use AI strictly for the easy stuff. Once they start to become over-reliant on the AI to generate code for more complex, important tasks, that’s when problems start to come up. 
    </p>
    
    <h3>Discussion</h3>
    <p>
        The findings of this report would indicate that generative AI use is, ultimately, a very dangerous thing. It excels at producing massive amounts of content nearly instantaneously, and that is something that’s great for programmers to utilize when they know what they’re doing, and they need the tool to complete simple, monotonous tasks that would otherwise take far too long. What AI isn’t so great for is complex tasks that require intricate knowledge of how the problem you’re facing needs to be solved, and you don’t have a great foundational knowledge of how to write and debug your own code. In most cases, people using generative AI fall into the second category, and that’s where a lot of problems are appearing. The idea of cognitive atrophy presented by Dr. Devine and others comes into play when programmers who don’t have a complex understanding of the problems they’re trying to solve become overly reliant on the machine to do the work for them. 
    </p>
    <p>
        The issue of whether or not generative AI is beneficial to programming work is not an easy one. It’s much more complex than “AI is good,” or “AI is bad.” AI is great for programmers to use in certain contexts, but it’s problematic when programmers base their entire knowledge on code written by an AI model, and unfortunately, that is a trend that is on the rise. It’s important for programmers to understand that there is an appropriate context where AI can be extremely beneficial to their work, but if they aren’t using it the way it’s meant to be used, it can cause much more harm than good. 
    </p>

    <h3>Conclusion</h3>
    <p>
        The topic of generative AI is certainly important, not only to programmers and creative workers, but to everybody. AI isn’t just a tool for creators, it’s become a mainstream thing. Artificial intelligence has grown to become so popular in 2024, every company is doing whatever they can just to get a slice of the AI pie. In focusing on AI, we can set ourselves up to understand it better, so that we can be less afraid of it, and use it to its full potential in the future. AI isn’t something that’s just going to go away. It’s becoming a part of our everyday lives, and it’s important to learn how to use it to our advantage rather than let it completely take over our work.
    </p>
    <p>
        It is the goal of this report to reach people who are curious about generative AI, what its benefits and drawbacks are, and how someone in the workforce in 2024 can take advantage of it so that they can improve the work they are already doing, rather than letting a machine do everything for them. In its current state, AI can’t do what humans do, but it isn’t going to be that way forever. As long as we can maintain an understanding and control of the tools we have at our disposal, we’ll stay ahead, and see vast improvements in our work beyond our imaginations.
    </p>

    <br><br> 

    <h3>Annotated Bibliography: Preface</h3>
    <p>
        This annotated bibliography was compiled for the purpose of analyzing the benefits and drawbacks of AI use, and whether utilization of advanced generative AI models for programmers is primarily beneficial or detrimental. The following sources both provide evidence supporting the claim that experienced programmers are greatly benefited by use of generative AI models. Sources organized alphabetically by last name. More sources may be added at a later time.
    </p>

    <br>

    <h3>Annotated Bibliography</h3>

    <br><p>Devine, Thomas. Personal Interview. 24 Oct. 2024.</p>

    <br><p>Peng, Sida, et al. “The Impact of AI on Developer Productivity: Evidence from Github Copilot.” arXiv, 13 Feb. 2023, https://doi.org/10.48550/arXiv.2302.06590. </p>
    <p>
        In this article, the author begins by suggesting that generative AI models are capable of significantly increasing the productivity of experienced programmers, and then goes on to explain what the abilities of AI models like GitHub Copilot are and how they benefit programmers, before introducing the experiment. 95 programmers took part in the experiment, and were tasked with writing an HTTP server in JavaScript as quickly as possible. 45 of them were given access to GitHub Copilot, a generative AI model capable of writing and debugging code, while the other 50 were restricted from AI use, but were still able to make use of internet searches, Stack Overflow, and other online resources. The participants were evaluated based on task success and completion time. The group with access to Copilot had an average completion time of 71.17 minutes, meanwhile the group without AI access completed the task in an average time of 160.89 minutes. 
    </p>
    <p>
        This article is used in the report to showcase that despite the flaws of and potential dangers in using generative AI for the purposes of programming, it can actually be greatly beneficial to programmers who are more experienced. “The group has an average coding experience of 6 years and, on average, reported spending 9 hours on coding in a working day.” (Peng et al. 5) Since the participants all knew what they were doing already, they were able to successfully use Copilot as a tool to accelerate their work. “Our results suggest that Copilot has statistically and practically significant impact on productivity: the treated group that hasaccess to GitHub Copilot was able to complete the task 55.8% faster than the control group.” (Peng et al. 7) This study suggests that AI use can be far more beneficial than detrimental to experienced programmers, and can therefore be a valuable source for a paper highlighting the pros and cons of AI use in the programming field.
    </p>

    <br>
    <p>Prather, James, et al. "The Widening Gap: The Benefits and Harms of Generative AI for Novice Programmers." ACM Conference on International Computing Education Research V.1 (ICER ’24 Vol. 1), 13–15 Aug. 2024, Melbourne, VIC, Australia. ACM, 2024, pp. 1–18. https://doi.org/10.1145/3632620.3671116.</p>
    <p>
        In this article, the author begins by introducing the concept of generative AI (GenAI) models as ‘personalized tutoring resources’ due to their ability to efficiently solve rudimentary programming problems. The author goes on to suggest that despite its ability to provide learners with quick and easy answers to any problem, GenAI may be causing learners to become too reliant on the tool, and it may actually result in their learning being stunted. “The recent ACM/IEEE-CS/AAAI CS2023 curriculum took an optimistic outlook on GenAI, suggesting that it may be able to scaffold novice learning. Indeed, early work showed that it could accelerate programming. However, since GenAI entered the mainstream, researchers have been concerned about the possibility of student over-reliance.” (Prather et al. 470) The author also suggests that GenAI over-reliance can be harmful to learners’ critical thinking skills. “If GenAI is replacing critical thinking in programming problem solving, rather than supporting it, then it stands to reason that metacognitive difficulties faced by novice programmers could get worse with GenAI tools as well.” (Prather et al. 470) In a previous study, programmers were evaluated for metacognitive difficulties–or difficulties understanding their own thought processes–in a programming problem solving environment. In this study, the element of GenAI is introduced in order to determine whether it solves the existing issues or makes them worse. By the end of the study, it is determined that students who are already successful with programming problem solving are greatly benefited by GenAI, whereas students who struggle are actually hindered by it, and gives them a false sense of programming problem solving ability.  
    </p>
    <p>
        This article is used in the report to highlight the duality of GenAI use as a programming tool versus its use as a crutch for struggling students. GenAI is something that is worrying to a lot of programmers, but studies like these demonstrate that there are indeed benefits as well as drawbacks, depending on the student’s initial level of understanding. “Our findings suggest that students who are already poised to succeed can leverage GenAI to accelerate, while struggling students may be hindered by using GenAI, leaving them with an illusion of competence…” (Prather et al. 484) Therefore, in the case of programming problem solving, it would certainly be more beneficial for the student to invest in a better ‘personalized tutoring resource’ than an AI model.
    </p>

    <br>
    <p>Y. Liu et al., ‘Refining ChatGPT-generated code: Characterizing and mitigating code quality issues’, ACM Trans. Softw. Eng. Methodol., 2023. https://doi.org/10.1145/3643674</p>
    <p>
        This article conducts an in-depth analysis of code written by ChatGPT, OpenAI’s generative AI model. ChatGPT’s performance on code generated was tested on a total of 2,033 programming tasks. The code was examined using various static analysis tools. The authors suggest, through evidence found in their analysis, that code generated by ChatGPT likely shouldn’t be used by programmers before being reviewed, as it commonly includes various bugs and logic errors. “Our findings demonstrate that while ChatGPT can generate functional code for various programming tasks, the generated code often suffers from quality issues, such as compilation errors, wrong outputs, maintainability problems, and performance insufficiencies” (Liu et al. 23).
    </p>
    <p>
        I think this article is very valuable for this research report, because while other sources may indicate that it’s okay for programmers who are more experienced and know what they are doing to incorporate AI-generated code into their work, the data found by this research indicates that all programmers, regardless of skill and experience level, should be wary of using AI-generated code, and it should always be reviewed before being put to use. While AI is better at generating accurate results for more similar problems, a larger data set like this one indicates that there can still be bugs and logic errors among simple results. 
    </p>

    <br>
    <p>
        Zhai, C., Wibowo, S. & Li, L.D. The effects of over-reliance on AI dialogue systems on students' cognitive abilities: a systematic review. Smart Learn. Environ. 11, 28 (2024). https://doi.org/10.1186/s40561-024-00316-7
    </p>
    <p>
        This article highlights the issue of over-reliance on AI models among students. The author begins with some background on AI models, their purposes, and ethical concerns raised by them. The author then suggests that AI use among students can lead to negative cognitive effects. “Research indicates that these ethical concerns could contribute to an over-reliance on AI dialogue systems, potentially impairing critical cognitive skills such as critical thinking, decision-making, and analytical thinking” (Zhai et al. 2). The author goes on to detail various studies that exhibit trends of cognitive atrophy among students who use generative AI for their work. 
    </p>
    <p>
        While this article does not focus specifically on the topic of AI for programmers, it’s important to look at how AI affects students in general, because as people are building a foundational concept for how they’re going to work in the future, it’s crucial that they are able to develop good critical thinking skills, no matter their field of study. Since studies highlighted by Zhai et al. in this article suggest that AI interrupts their ability to develop good critical thinking skills, it is beneficial for my report to include this research, as generative AI use is, arguably, more common among students in Computer Science fields, due to its ability to generate massive amount of code almost instantaneously. 
    </p>

</body>
</html>